{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for the Beijing Air Quality 2.5 Dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43824 41757\n"
     ]
    }
   ],
   "source": [
    "dataset_link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv'\n",
    "df = pd.read_csv(dataset_link)\n",
    "\n",
    "print(len(df), len(df.dropna()))\n",
    "\n",
    "df_temp = df.copy()\n",
    "df_temp = df_temp.dropna()\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "\n",
    "# df['Datetime'] = pd.to_datetime(df[['day', 'month', 'year']]) + pd.to_timedelta(df['hour'], 'h')\n",
    "\n",
    "df_temp = df_temp.drop(['index', 'No', 'day', 'month', 'year', 'hour'], axis=1)\n",
    "df_temp['cbwd'] = df_temp['cbwd'].astype('category').cat.codes\n",
    "\n",
    "# for feature_name in df_temp.columns:\n",
    "#    max_value = df_temp[feature_name].max()\n",
    "#    min_value = df_temp[feature_name].min()\n",
    "    \n",
    "#    df_temp[feature_name] = (df_temp[feature_name] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>109.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm2.5  DEWP  TEMP    PRES  cbwd    Iws  Is  Ir\n",
       "0  129.0   -16  -4.0  1020.0     2   1.79   0   0\n",
       "1  148.0   -15  -4.0  1020.0     2   2.68   0   0\n",
       "2  159.0   -11  -5.0  1021.0     2   3.57   0   0\n",
       "3  181.0    -7  -5.0  1022.0     2   5.36   1   0\n",
       "4  138.0    -7  -5.0  1022.0     2   6.25   2   0\n",
       "5  109.0    -7  -6.0  1022.0     2   7.14   3   0\n",
       "6  105.0    -7  -6.0  1023.0     2   8.93   4   0\n",
       "7  124.0    -7  -5.0  1024.0     2  10.72   0   0\n",
       "8  120.0    -8  -6.0  1024.0     2  12.51   0   0\n",
       "9  132.0    -7  -5.0  1025.0     2  14.30   0   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33405 8351\n",
      "33405 33405 8351 8351\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df_temp) * 0.8)\n",
    "\n",
    "train = df_temp.iloc[:train_size]\n",
    "test = df_temp.iloc[train_size + 1:]\n",
    "\n",
    "X_train = train.drop(['pm2.5'], axis=1)\n",
    "y_train = train['pm2.5']\n",
    "\n",
    "X_test = test.drop(['pm2.5'], axis=1)\n",
    "y_test = test['pm2.5']\n",
    "\n",
    "print(len(train), len(test))\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, n_steps=24):\n",
    "    dataset = []\n",
    "    \n",
    "    for i in range(len(X) - (n_steps + 2)):\n",
    "        sample = [\n",
    "            X.iloc[i:i + n_steps].values,\n",
    "            y.iloc[i + n_steps + 1]\n",
    "        ]\n",
    "        \n",
    "        dataset.append(sample)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, n_steps=24):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.internal_dataset = create_sequences(X, y, n_steps=24)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.internal_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.internal_dataset[idx][0]\n",
    "        label = self.internal_dataset[idx][1]\n",
    "        \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = StepDataset(X_train, y_train)\n",
    "dataset_test = StepDataset(X_test, y_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=12, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Sequential(\n",
    "            nn.Conv1d(7, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2d = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(20 * 64, 50),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        x = self.conv2d(x)\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, dataloader_train, criterion):\n",
    "    running_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(dataloader_train):\n",
    "        inputs = inputs.float().permute(0, 2, 1).to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds.reshape(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def validator(model, dataloader_test, criterion):\n",
    "    running_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(dataloader_test):\n",
    "        inputs = inputs.float().permute(0, 2, 1).to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds.reshape(-1), labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "    \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 17.20979735870142\n",
      "Train 72.1130561766909\n",
      "Train 69.7252706415271\n",
      "Train 67.74193376932617\n",
      "Train 66.14478687396759\n",
      "Train 65.23106870421567\n",
      "Train 64.41461335070093\n",
      "Train 63.49323950004098\n",
      "Train 62.4588500299872\n",
      "Train 60.82255411542293\n",
      "Train 59.935821759537944\n",
      "Validation 23.175282975652078\n",
      "Train 59.37668974394425\n",
      "Train 58.68498785233515\n",
      "Train 58.496706160343784\n",
      "Train 57.997851409644724\n",
      "Train 57.63929932439696\n",
      "Train 57.56376549967924\n",
      "Train 56.88487082861209\n",
      "Train 56.65983217324737\n",
      "Train 56.54654724284267\n",
      "Train 56.241874590612504\n",
      "Validation 19.869856063193506\n",
      "Train 55.86395411230865\n",
      "Train 55.55405891378692\n",
      "Train 55.43719615051851\n",
      "Train 55.2940942348978\n",
      "Train 55.09492959006067\n",
      "Train 54.82911273697826\n",
      "Train 54.549565406603236\n",
      "Train 54.6026450374159\n",
      "Train 54.46109511704859\n",
      "Train 54.049689936003695\n",
      "Validation 18.01911223594616\n",
      "Train 54.03979208082025\n",
      "Train 53.906990641231246\n",
      "Train 53.595165890039596\n",
      "Train 53.801030064640415\n",
      "Train 53.59783404255668\n",
      "Train 53.463068065927835\n",
      "Train 53.22250639303908\n",
      "Train 53.06417741285306\n",
      "Train 52.9328948125661\n",
      "Train 52.899824911360255\n",
      "Validation 15.828030466861986\n",
      "Train 52.95496007369458\n",
      "Train 52.836132006710336\n",
      "Train 52.66057040878203\n",
      "Train 52.50720176895602\n",
      "Train 52.41895497299458\n",
      "Train 52.56039806598386\n",
      "Train 52.450962463357655\n",
      "Train 52.3584319228838\n",
      "Train 52.46482895613574\n",
      "Train 52.12665082669618\n",
      "Validation 14.405582364645902\n",
      "Train 52.214015646515605\n",
      "Train 52.021339728196345\n",
      "Train 52.039970038864446\n",
      "Train 51.92384108213278\n",
      "Train 51.88732896409902\n",
      "Train 51.91195992280218\n",
      "Train 51.88371314872177\n",
      "Train 51.75470853940263\n",
      "Train 51.73720958214025\n",
      "Train 51.75811387651006\n",
      "Validation 14.026572551939832\n",
      "Train 51.50095852170378\n",
      "Train 51.531269703470144\n",
      "Train 51.579103907263594\n",
      "Train 51.4985128224196\n",
      "Train 51.56475090432047\n",
      "Train 51.257827746962406\n",
      "Train 51.20215527030909\n",
      "Train 51.22908463587785\n",
      "Train 51.19875159317602\n",
      "Train 51.19523504395694\n",
      "Validation 13.647182091545664\n",
      "Train 51.203890602165295\n",
      "Train 50.98873039512305\n",
      "Train 51.220924524674736\n",
      "Train 51.15243083508558\n",
      "Train 51.10214304786891\n",
      "Train 51.00751137947711\n",
      "Train 50.90307838825936\n",
      "Train 51.26589659107066\n",
      "Train 51.012704204090376\n",
      "Train 50.711368985993666\n",
      "Validation 13.484350896412996\n",
      "Train 50.72649726106656\n",
      "Train 50.69613248551175\n",
      "Train 50.92333295446433\n",
      "Train 50.71024315165239\n",
      "Train 50.7411063978091\n",
      "Train 50.58738968185518\n",
      "Train 50.63058268286871\n",
      "Train 50.53086581108469\n",
      "Train 50.46288248568795\n",
      "Train 50.51062597969639\n",
      "Validation 13.327545367068819\n",
      "Train 50.482036014326525\n",
      "Train 50.413431146777334\n",
      "Train 50.42404554474705\n",
      "Train 50.277172637962764\n",
      "Train 50.265045238518184\n",
      "Train 50.30888905232112\n",
      "Train 50.075823478009696\n",
      "Train 50.306337776070954\n",
      "Train 50.164160380982224\n",
      "Train 49.886487859003324\n",
      "Validation 13.28010068892747\n",
      "Train 49.80484432526238\n",
      "Train 49.81026274364343\n",
      "Train 49.95439135754049\n",
      "Train 49.79664204705113\n",
      "Train 49.62437651878977\n",
      "Train 49.871657159455296\n",
      "Train 49.839257526791926\n",
      "Train 49.82377721027536\n",
      "Train 49.88775663385282\n",
      "Train 49.64282709882895\n",
      "Validation 13.095132826644683\n",
      "Train 49.64805091335823\n",
      "Train 49.753623965273306\n",
      "Train 49.56261275707604\n",
      "Train 49.678515047370574\n",
      "Train 49.465153304901506\n",
      "Train 49.560791112037975\n",
      "Train 49.268268552210415\n",
      "Train 49.49881603373288\n",
      "Train 49.371746901168315\n",
      "Train 49.2301538378793\n",
      "Validation 13.102391772523877\n",
      "Train 49.44513917612053\n",
      "Train 49.157551992205214\n",
      "Train 49.4583493746244\n",
      "Train 49.21546938340498\n",
      "Train 49.074695468505965\n",
      "Train 48.987156866095546\n",
      "Train 49.15681216024307\n",
      "Train 48.892486601146665\n",
      "Train 48.87912478179575\n",
      "Train 48.65193993765874\n",
      "Validation 13.14781633432952\n",
      "Train 48.89584066249071\n",
      "Train 49.03306642442534\n",
      "Train 48.82092821486643\n",
      "Train 48.938406783329505\n",
      "Train 48.70685668003636\n",
      "Train 48.59762507852764\n",
      "Train 48.88722621374727\n",
      "Train 48.67366327646394\n",
      "Train 48.634626701270655\n",
      "Train 48.63334680443441\n",
      "Validation 13.13641248462356\n",
      "Train 48.55032890396612\n",
      "Train 48.592095204431494\n",
      "Train 48.42650038325298\n",
      "Train 48.29356986404237\n",
      "Train 48.335953817017895\n",
      "Train 48.214960576260715\n",
      "Train 48.26237384652509\n",
      "Train 48.38303599350749\n",
      "Train 48.2979042769164\n",
      "Train 48.26368159762738\n",
      "Validation 13.082800319947243\n",
      "Train 48.350520054185075\n",
      "Train 48.061782776838065\n",
      "Train 47.98902088690798\n",
      "Train 48.00382078285272\n",
      "Train 48.18658215107462\n",
      "Train 48.074104653811986\n",
      "Train 48.02989479940114\n",
      "Train 47.99371094724243\n",
      "Train 47.84241096944281\n",
      "Train 48.05903419798694\n",
      "Validation 12.974921136044667\n",
      "Train 48.12776508972338\n",
      "Train 47.77427390262774\n",
      "Train 47.83206273642141\n",
      "Train 47.59900485462289\n",
      "Train 47.72724394584885\n",
      "Train 47.660895747773345\n",
      "Train 47.595702948028624\n",
      "Train 47.786015258985486\n",
      "Train 47.71727674102543\n",
      "Train 47.79043718913234\n",
      "Validation 12.764155740707062\n",
      "Train 47.543471694206865\n",
      "Train 47.53774325857053\n",
      "Train 47.40445908447721\n",
      "Train 47.53874019578924\n",
      "Train 47.61380460012053\n",
      "Train 47.49908573236678\n",
      "Train 47.362572884748175\n",
      "Train 47.64355705330305\n",
      "Train 47.42509866553532\n",
      "Train 47.358256916105105\n",
      "Validation 12.697463895073046\n",
      "Train 47.127898282236885\n",
      "Train 47.32963420875976\n",
      "Train 47.25389405123027\n",
      "Train 47.207283448907305\n",
      "Train 47.44698769364059\n",
      "Train 47.175660707554655\n",
      "Train 47.25277246724436\n",
      "Train 47.20940616831858\n",
      "Train 47.41789806137661\n",
      "Train 47.18596129024054\n",
      "Validation 12.712958192585356\n",
      "Train 47.07456260092562\n",
      "Train 47.11096294208193\n",
      "Train 46.997091768029605\n",
      "Train 47.054379456425465\n",
      "Train 47.0993245620251\n",
      "Train 47.06511992408936\n",
      "Train 47.02867354895039\n",
      "Train 47.077319189681155\n",
      "Train 47.13904360410209\n",
      "Train 47.03325732640445\n",
      "Validation 12.603433383016771\n",
      "Train 46.965499975028266\n",
      "Train 46.925732532308565\n",
      "Train 46.7823702287194\n",
      "Train 47.00674390972818\n",
      "Train 46.85219638245642\n",
      "Train 46.849772794138694\n",
      "Train 46.72030406041937\n",
      "Train 46.811050931812616\n",
      "Train 46.76847511709894\n",
      "Train 46.77547416024547\n",
      "Validation 12.581268488161003\n",
      "Train 46.67951225763084\n",
      "Train 46.746940286745705\n",
      "Train 46.78288520847954\n",
      "Train 46.551080169907415\n",
      "Train 46.419525124716465\n",
      "Train 46.73400583993951\n",
      "Train 46.89562036278092\n",
      "Train 46.5401800193005\n",
      "Train 46.47663551071923\n",
      "Train 46.66205839143221\n",
      "Validation 12.419796035325758\n",
      "Train 46.534882996769625\n",
      "Train 46.63851270257441\n",
      "Train 46.52959769728542\n",
      "Train 46.43552916942099\n",
      "Train 46.35936498204896\n",
      "Train 46.24910375370901\n",
      "Train 46.39575243017641\n",
      "Train 46.241176658487426\n",
      "Train 46.23789464784645\n",
      "Train 46.28896777137932\n",
      "Validation 12.269954433122356\n",
      "Train 46.176514443693016\n",
      "Train 46.33271075079203\n",
      "Train 46.35201559428428\n",
      "Train 46.09553135529771\n",
      "Train 46.090002413536475\n",
      "Train 46.04775050387461\n",
      "Train 46.168875865032994\n",
      "Train 46.01526243801515\n",
      "Train 46.078250255540155\n",
      "Train 46.088162341321826\n",
      "Validation 12.430092290097393\n",
      "Train 46.28288649659976\n",
      "Train 45.80362869251726\n",
      "Train 45.94763094658135\n",
      "Train 45.85633549083487\n",
      "Train 45.94837203084094\n",
      "Train 45.99759106881151\n",
      "Train 45.82100303407884\n",
      "Train 45.99534941062406\n",
      "Train 45.995426909431636\n",
      "Train 46.05597604580872\n",
      "Validation 12.436582953273437\n",
      "Train 46.07955006671243\n",
      "Train 45.719543995487015\n",
      "Train 45.75622657444904\n",
      "Train 45.816717241754816\n",
      "Train 45.688386544060315\n",
      "Train 45.68924655762617\n",
      "Train 45.651568200757914\n",
      "Train 45.804352401487265\n",
      "Train 45.54848525680114\n",
      "Train 45.62526391381244\n",
      "Validation 12.462500765459046\n",
      "Train 45.63608061958782\n",
      "Train 45.532205295725575\n",
      "Train 45.52629120327602\n",
      "Train 45.664159698978246\n",
      "Train 45.31429682812358\n",
      "Train 45.389533539755924\n",
      "Train 45.63735125079419\n",
      "Train 45.506232846520255\n",
      "Train 45.42185250903787\n",
      "Train 45.584709201717786\n",
      "Validation 12.254465582343334\n",
      "Train 45.63303943078009\n",
      "Train 45.42418491446141\n",
      "Train 45.543915208812074\n",
      "Train 45.41265607462951\n",
      "Train 45.23589446722904\n",
      "Train 45.37201565054147\n",
      "Train 45.197885331920716\n",
      "Train 45.17206320781489\n",
      "Train 45.50079924001015\n",
      "Train 45.283925435596196\n",
      "Validation 12.393908297989885\n",
      "Train 45.14333861873443\n",
      "Train 45.01329928452295\n",
      "Train 45.130720345773426\n",
      "Train 45.16112784118982\n",
      "Train 45.04582638204055\n",
      "Train 45.134775539296385\n",
      "Train 45.44295986032075\n",
      "Train 44.96189851490051\n",
      "Train 45.228661609415866\n",
      "Train 45.17386429250712\n",
      "Validation 12.342659523039735\n",
      "Train 45.05862101280458\n",
      "Train 45.027692875786705\n",
      "Train 45.07577135796859\n",
      "Train 45.057332188340936\n",
      "Train 45.09417158613781\n",
      "Train 44.93730132966312\n",
      "Train 45.20069272161644\n",
      "Train 44.94425610742665\n",
      "Train 45.01207617360169\n",
      "Train 44.855920389219634\n",
      "Validation 12.474785161909656\n",
      "Train 44.8691582468497\n",
      "Train 45.077008970858465\n",
      "Train 44.90667576403347\n",
      "Train 44.91719627136125\n",
      "Train 45.056119248603075\n",
      "Train 44.77788601308997\n",
      "Train 44.965098674694985\n",
      "Train 44.90342361497673\n",
      "Train 45.14868808808214\n",
      "Train 45.020558091396055\n",
      "Validation 12.233092838615757\n",
      "Train 44.78910908190832\n",
      "Train 44.66999903053453\n",
      "Train 44.81968749272232\n",
      "Train 44.711545975965876\n",
      "Train 44.65080644499904\n",
      "Train 44.69539193885092\n",
      "Train 44.620243204145616\n",
      "Train 44.3693463466392\n",
      "Train 44.54584822459327\n",
      "Train 44.82010626030174\n",
      "Validation 12.269360674361716\n",
      "Train 44.57029152709233\n",
      "Train 44.917379106616565\n",
      "Train 44.743267921001085\n",
      "Train 44.542073897412145\n",
      "Train 44.79262542797455\n",
      "Train 44.577247384509796\n",
      "Train 44.481361380033064\n",
      "Train 44.49286953272535\n",
      "Train 44.60521739961259\n",
      "Train 44.36963684022384\n",
      "Validation 12.183260975168558\n",
      "Train 44.67095999491463\n",
      "Train 44.35740070528131\n",
      "Train 44.600867457821764\n",
      "Train 44.50242077511562\n",
      "Train 44.35174937195953\n",
      "Train 44.63459419899926\n",
      "Train 44.69890588461967\n",
      "Train 44.430835602482304\n",
      "Train 44.41587660828569\n",
      "Train 44.45959547219904\n",
      "Validation 12.19754869195731\n",
      "Train 44.297328194639476\n",
      "Train 44.401085039551184\n",
      "Train 44.49347450388669\n",
      "Train 44.505335695189935\n",
      "Train 44.355249467511385\n",
      "Train 44.50919638388796\n",
      "Train 44.498255091549936\n",
      "Train 44.53326483183332\n",
      "Train 44.38522339265695\n",
      "Train 44.149306749886186\n",
      "Validation 12.064060027611333\n",
      "Train 44.194359868872006\n",
      "Train 44.096846540226174\n",
      "Train 44.254999435822114\n",
      "Train 44.41658933513204\n",
      "Train 44.18141310284414\n",
      "Train 44.47962524692075\n",
      "Train 44.302234460260266\n",
      "Train 44.364131926290426\n",
      "Train 44.261463711494855\n",
      "Train 44.06432531211635\n",
      "Validation 12.139879453619292\n",
      "Train 44.09664813153269\n",
      "Train 44.216426618659696\n",
      "Train 44.338024658877416\n",
      "Train 44.18696578786495\n",
      "Train 44.087814458705466\n",
      "Train 44.03629180799707\n",
      "Train 44.191222902556106\n",
      "Train 44.00307645174687\n",
      "Train 44.189082691731166\n",
      "Train 44.06368477129405\n",
      "Validation 12.033732632867387\n",
      "Train 44.113236466386525\n",
      "Train 43.99585935231338\n",
      "Train 44.03348462269685\n",
      "Train 43.966629154471335\n",
      "Train 44.01941676576047\n",
      "Train 44.05266290041802\n",
      "Train 44.104219068305085\n",
      "Train 43.88457788129576\n",
      "Train 43.806179843730504\n",
      "Train 43.973516712636076\n",
      "Validation 12.091442666149756\n",
      "Train 43.791450675659945\n",
      "Train 43.857492041365006\n",
      "Train 43.91496753804037\n",
      "Train 43.80111832116509\n",
      "Train 43.90833909600695\n",
      "Train 43.81522479831187\n",
      "Train 43.738994916937145\n",
      "Train 43.87625613069466\n",
      "Train 43.7098048357206\n",
      "Train 43.800336433519654\n",
      "Validation 12.233000053166487\n",
      "Train 43.84695851978512\n",
      "Train 43.819498916995514\n",
      "Train 43.98365071867971\n",
      "Train 43.80854572511079\n",
      "Train 43.6727417659451\n",
      "Train 43.64307260641856\n",
      "Train 43.66625024027999\n",
      "Train 43.67510566186082\n",
      "Train 43.812544748347754\n",
      "Train 43.73968445556272\n",
      "Validation 12.087125423227087\n",
      "Train 43.73434270692334\n",
      "Train 43.75931691502085\n",
      "Train 43.75424576589823\n",
      "Train 43.810645467638544\n",
      "Train 43.67143253646764\n",
      "Train 43.55054604197303\n",
      "Train 43.763550787242856\n",
      "Train 43.853888533297074\n",
      "Train 43.551173858682\n",
      "Train 43.613370837409406\n",
      "Validation 12.133395101765263\n",
      "Train 43.339703077382104\n",
      "Train 43.81155880915013\n",
      "Train 43.45550620735849\n",
      "Train 43.39404626354565\n",
      "Train 43.611383549349505\n",
      "Train 43.73956985494201\n",
      "Train 43.63399885876585\n",
      "Train 43.39939175425118\n",
      "Train 43.344148057129296\n",
      "Train 43.53061921668515\n",
      "Validation 12.186322196964563\n",
      "Train 43.44274510615683\n",
      "Train 43.59597772801205\n",
      "Train 43.43785851071157\n",
      "Train 43.537151790710766\n",
      "Train 43.47231619800277\n",
      "Train 43.31298199015329\n",
      "Train 43.619446645530324\n",
      "Train 43.444958005295994\n",
      "Train 43.4377734599398\n",
      "Train 43.609492060180024\n",
      "Validation 12.266370151301754\n",
      "Train 43.381614083270215\n",
      "Train 43.45851864633073\n",
      "Train 43.65905702936829\n",
      "Train 43.392578841241296\n",
      "Train 43.24609852419921\n",
      "Train 43.46959614839424\n",
      "Train 43.35185720790298\n",
      "Train 43.53502696024095\n",
      "Train 43.58320045436911\n",
      "Train 43.19777605183942\n",
      "Validation 12.173479897782238\n",
      "Train 43.05102942265854\n",
      "Train 43.41707551899272\n",
      "Train 43.38987791388263\n",
      "Train 43.43052639411046\n",
      "Train 43.24268834458933\n",
      "Train 43.0826101387087\n",
      "Train 42.83519746359949\n",
      "Train 43.21182311652463\n",
      "Train 43.226774901473036\n",
      "Train 43.08865612501039\n",
      "Validation 12.14954442715662\n",
      "Train 43.33963801687695\n",
      "Train 43.14251334747764\n",
      "Train 43.17311934461532\n",
      "Train 43.18272576265246\n",
      "Train 43.13518949406855\n",
      "Train 42.85871409367178\n",
      "Train 43.17686125025485\n",
      "Train 42.782453523360935\n",
      "Train 42.877945854884956\n",
      "Train 42.90943727974923\n",
      "Validation 12.251950372216687\n",
      "Train 43.02224706553624\n",
      "Train 43.199045714502454\n",
      "Train 42.938921174499136\n",
      "Train 43.00589187140091\n",
      "Train 42.972256372679404\n",
      "Train 43.06526846687713\n",
      "Train 42.74733544595802\n",
      "Train 42.881993973323716\n",
      "Train 42.828906030555494\n",
      "Train 42.84227251055256\n",
      "Validation 12.319464509132352\n",
      "Train 42.904022106928934\n",
      "Train 42.96274546480796\n",
      "Train 42.96738960381295\n",
      "Train 42.916656127942716\n",
      "Train 42.998868831107295\n",
      "Train 42.85349586719579\n",
      "Train 42.810742821820256\n",
      "Train 42.69224340186369\n",
      "Train 42.77175000856284\n",
      "Train 42.829574558993706\n",
      "Validation 12.317621190885603\n",
      "Train 42.7697617725277\n",
      "Train 42.793392699798346\n",
      "Train 42.93580789183816\n",
      "Train 42.71931344904889\n",
      "Train 43.05128671581328\n",
      "Train 42.82890046114205\n",
      "Train 42.69943394367854\n",
      "Train 42.94020861378683\n",
      "Train 42.76517112738447\n",
      "Train 42.64520242135359\n",
      "Validation 12.220227991394822\n",
      "Train 42.6324244019027\n",
      "Train 42.6388248417722\n",
      "Train 42.87844106475712\n",
      "Train 42.74582753988756\n",
      "Train 42.851491113260956\n",
      "Train 42.769946279926835\n",
      "Train 42.88455144061535\n",
      "Train 42.621159804287274\n",
      "Train 42.45323025867461\n",
      "Train 42.568579827085145\n",
      "Validation 12.265839105111759\n",
      "Train 42.63374030324386\n",
      "Train 42.60996096782081\n",
      "Train 42.54144408928242\n",
      "Train 42.55807832965398\n",
      "Train 42.61501668448246\n",
      "Train 42.5842664084102\n",
      "Train 42.73408010004237\n",
      "Train 42.36200537182803\n",
      "Train 42.46729560681678\n",
      "Train 42.58197886154516\n",
      "Validation 12.526202434519913\n",
      "Train 42.59895546675414\n",
      "Train 42.45838968930357\n",
      "Train 42.463631630243796\n",
      "Train 42.559406100718085\n",
      "Train 42.40065055785635\n",
      "Train 42.420994120780556\n",
      "Train 42.529953470982555\n",
      "Train 42.57524458390187\n",
      "Train 42.3544730094163\n",
      "Train 42.41541967925024\n",
      "Validation 12.35083577420367\n",
      "Train 42.3744428580738\n",
      "Train 42.387361579066464\n",
      "Train 42.54237278985257\n",
      "Train 42.52085337614859\n",
      "Train 42.40004349770433\n",
      "Train 42.49022220395436\n",
      "Train 42.34503967101243\n",
      "Train 42.440453677748195\n",
      "Train 42.27135011504487\n",
      "Train 42.44771987701131\n",
      "Validation 12.520500218499743\n",
      "Train 42.29721881176052\n",
      "Train 42.34128484504845\n",
      "Train 42.23580708326323\n",
      "Train 42.271216347395814\n",
      "Train 42.37007873676219\n",
      "Train 42.30727986836074\n",
      "Train 42.188422760802325\n",
      "Train 42.33230497149749\n",
      "Train 42.294092229079375\n",
      "Train 42.173088165429924\n",
      "Validation 12.433433661951083\n",
      "Train 42.46938300921195\n",
      "Train 42.09735339730014\n",
      "Train 42.200667782707406\n",
      "Train 42.309372221583686\n",
      "Train 42.11458344454392\n",
      "Train 42.189659482022144\n",
      "Train 42.327743541800146\n",
      "Train 42.047946340612675\n",
      "Train 42.170865559817905\n",
      "Train 42.14339781600224\n",
      "Validation 12.492308448665353\n",
      "Train 42.28306537635201\n",
      "Train 42.08750058570241\n",
      "Train 42.16863504598502\n",
      "Train 42.262226516098366\n",
      "Train 42.107699056395006\n",
      "Train 42.20052478953628\n",
      "Train 42.087638532875424\n",
      "Train 42.19044449451928\n",
      "Train 42.15341269327187\n",
      "Train 42.03630476928631\n",
      "Validation 12.549209219015905\n",
      "Train 42.167603721042745\n",
      "Train 42.095247455546534\n",
      "Train 41.948561842410705\n",
      "Train 42.07593088052326\n",
      "Train 42.056540800460716\n",
      "Train 42.05678233150781\n",
      "Train 42.0444143741873\n",
      "Train 41.88821859101783\n",
      "Train 42.27054286971528\n",
      "Train 42.03079568499888\n",
      "Validation 12.597928976344171\n",
      "Train 42.238207188465026\n",
      "Train 41.85461948168184\n",
      "Train 42.128775654209335\n",
      "Train 42.21114115253101\n",
      "Train 42.045996626018194\n",
      "Train 42.053892248316174\n",
      "Train 42.02935295084412\n",
      "Train 41.78757093948567\n",
      "Train 41.92027530024842\n",
      "Train 41.82811779803633\n",
      "Validation 12.58694353984638\n",
      "Train 42.038949032167494\n",
      "Train 41.9687747191303\n",
      "Train 41.85309734638435\n",
      "Train 41.785385950146434\n",
      "Train 41.919574124319446\n",
      "Train 41.944581943394724\n",
      "Train 41.95374191638636\n",
      "Train 41.79978091643064\n",
      "Train 41.92029896894862\n",
      "Train 41.97370557220268\n",
      "Validation 12.620929751269342\n",
      "Train 41.960345057426466\n",
      "Train 41.789177055370885\n",
      "Train 41.73099975942451\n",
      "Train 41.92568392791309\n",
      "Train 41.793867244813015\n",
      "Train 41.891844923422546\n",
      "Train 41.73802031423444\n",
      "Train 41.579667258656855\n",
      "Train 41.71340517861478\n",
      "Train 41.733440816273884\n",
      "Validation 12.637962002620519\n",
      "Train 41.93816388390375\n",
      "Train 41.61089071329338\n",
      "Train 41.738971535804716\n",
      "Train 41.713165602522906\n",
      "Train 41.83694498081331\n",
      "Train 41.87522714053188\n",
      "Train 41.72340033236037\n",
      "Train 41.73090279796499\n",
      "Train 41.79569571991776\n",
      "Train 41.7916187985521\n",
      "Validation 12.73500922770058\n",
      "Train 41.642842155450715\n",
      "Train 41.39121186836086\n",
      "Train 41.73736014694383\n",
      "Train 41.58892899850219\n",
      "Train 41.98427974329331\n",
      "Train 41.73919425012395\n",
      "Train 41.592399594254154\n",
      "Train 41.6898043729863\n",
      "Train 41.56700912779994\n",
      "Train 41.78978041673547\n",
      "Validation 12.54771940636172\n",
      "Train 41.6238759095338\n",
      "Train 41.56108339179085\n",
      "Train 41.50860573686686\n",
      "Train 41.7546769881917\n",
      "Train 41.79258387273889\n",
      "Train 41.497739520542574\n",
      "Train 41.46524107310517\n",
      "Train 41.70527947728879\n",
      "Train 41.39526234720355\n",
      "Train 41.682085310272996\n",
      "Validation 12.62476405053581\n",
      "Train 41.584018635158486\n",
      "Train 41.56112443805169\n",
      "Train 41.597078672422086\n",
      "Train 41.75900795912246\n",
      "Train 41.68703314522716\n",
      "Train 41.67351065557865\n",
      "Train 41.55964511354393\n",
      "Train 41.2921676809714\n",
      "Train 41.36916512426586\n",
      "Train 41.52884122752869\n",
      "Validation 12.600515943564245\n",
      "Train 41.60708829252776\n",
      "Train 41.42368832746913\n",
      "Train 41.190857621253954\n",
      "Train 41.39005202757721\n",
      "Train 41.50571521188954\n",
      "Train 41.52488653716383\n",
      "Train 41.46940043510763\n",
      "Train 41.41441221463432\n",
      "Train 41.396488992110335\n",
      "Train 41.57582317857242\n",
      "Validation 12.491037584568081\n",
      "Train 41.1810561755336\n",
      "Train 41.59735342755239\n",
      "Train 41.64332913135471\n",
      "Train 41.15875461211228\n",
      "Train 41.83649502753526\n",
      "Train 41.21287324041192\n",
      "Train 41.44144900251343\n",
      "Train 41.42157940068406\n",
      "Train 41.305258183835825\n",
      "Train 40.919163470042\n",
      "Validation 12.518080548962443\n",
      "Train 41.38778419832288\n",
      "Train 41.175064400320515\n",
      "Train 41.31420085307594\n",
      "Train 41.4624784939757\n",
      "Train 41.58375574675161\n",
      "Train 41.447671059221776\n",
      "Train 41.25727176113492\n",
      "Train 41.17254297292807\n",
      "Train 41.41832437329289\n",
      "Train 41.42250649762788\n",
      "Validation 12.580037350280948\n",
      "Train 41.4108225508271\n",
      "Train 41.412989429052914\n",
      "Train 41.35922143666715\n",
      "Train 41.21365403584831\n",
      "Train 41.47398506875179\n",
      "Train 41.61542191349457\n",
      "Train 41.355131336118916\n",
      "Train 41.44541999849803\n",
      "Train 41.10658469669772\n",
      "Train 41.30903474111338\n",
      "Validation 12.498254888097131\n",
      "Train 41.23746127160139\n",
      "Train 41.34471255827944\n",
      "Train 41.31240667678057\n",
      "Train 41.22057106510329\n",
      "Train 41.24630775064294\n",
      "Train 41.19121895463753\n",
      "Train 41.40312225286434\n",
      "Train 41.15909315698186\n",
      "Train 41.273304065039994\n",
      "Train 41.383509260728836\n",
      "Validation 12.551380410115552\n",
      "Train 40.95272576530403\n",
      "Train 41.19150655651847\n",
      "Train 41.25667497924898\n",
      "Train 41.06507825602909\n",
      "Train 41.07397250285858\n",
      "Train 41.29913401595129\n",
      "Train 41.23493904402409\n",
      "Train 41.34949788757574\n",
      "Train 41.238120327228955\n",
      "Train 41.43181356417027\n",
      "Validation 12.564126330001331\n",
      "Train 41.3468678684478\n",
      "Train 40.89401785076993\n",
      "Train 41.22258339221318\n",
      "Train 41.018248642802156\n",
      "Train 41.043417046945954\n",
      "Train 41.03897208031093\n",
      "Train 41.01563246716363\n",
      "Train 41.10575923981382\n",
      "Train 41.13516908892618\n",
      "Train 41.30655637437024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ec30c74c80d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1c3bf38d2f9c>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, dataloader_train, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6ad3c5fa2fc6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    256\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 258\u001b[0;31m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    259\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = trainer(model, dataloader_train, loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Validation', validator(model, dataloader_test, loss))\n",
    "    print('Train', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
